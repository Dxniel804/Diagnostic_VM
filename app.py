"""
Sistema de An√°lise Estrat√©gica de Follow-ups de Vendas
Automa√ß√£o que l√™ planilhas Excel e gera estrat√©gias personalizadas usando IA
"""

import os
import time
import logging
import hashlib
import pandas as pd
from flask import Flask, render_template, request, flash, redirect, url_for, session, make_response
from groq import Groq
from dotenv import load_dotenv
import tempfile
from werkzeug.utils import secure_filename
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors
from datetime import datetime
import io

# Carrega vari√°veis de ambiente
load_dotenv()

# ==================== CONFIGURA√á√ÉO ====================
app = Flask(__name__)
app.secret_key = os.getenv('SECRET_KEY', os.urandom(24).hex())
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max

ALLOWED_EXTENSIONS = {'xlsx', 'xls', 'csv'}

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Configura√ß√µes da API Groq (GRATUITA - Recomendada)
GROQ_API_KEY = os.getenv('GROQ_API_KEY')
GROQ_MODEL = os.getenv('GROQ_MODEL', 'llama-3.3-70b-versatile')
MAX_RETRIES = int(os.getenv('MAX_RETRIES', '3'))
RETRY_DELAY = int(os.getenv('RETRY_DELAY', '5'))
REQUEST_DELAY = float(os.getenv('REQUEST_DELAY', '10'))

# Cache para evitar requisi√ß√µes duplicadas
cache_analises = {}

if not GROQ_API_KEY:
    logger.error("GROQ_API_KEY n√£o encontrada nas vari√°veis de ambiente")
    raise ValueError("GROQ_API_KEY √© obrigat√≥ria. Configure no arquivo .env")

# Inicializa o cliente Groq
try:
    client = Groq(api_key=GROQ_API_KEY)
    logger.info(f"Cliente Groq configurado com sucesso usando modelo: {GROQ_MODEL}")
except Exception as e:
    logger.error(f"Erro ao configurar cliente Groq: {str(e)}")
    raise ValueError("N√£o foi poss√≠vel configurar o cliente Groq. Verifique sua API key.")


# ==================== FUN√á√ïES AUXILIARES ====================

def allowed_file(filename):
    """Verifica se o arquivo tem extens√£o permitida"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


def gerar_hash_cache(dados_negocio):
    """Gera um hash √∫nico para os dados do neg√≥cio (evita requisi√ß√µes duplicadas)"""
    dados_str = f"{dados_negocio['negocio']}|{dados_negocio['empresa']}|{dados_negocio['fase']}"
    for i in range(1, 6):
        dados_str += f"|{dados_negocio['historico_descricoes'][f'D{i}']}"
        dados_str += f"|{dados_negocio['historico_temperaturas'][f'F{i}']}"
    return hashlib.md5(dados_str.encode()).hexdigest()


def identificar_ultimo_followup(dados_negocio):
    """
    REGRA DE OURO: Identifica onde a conversa parou.
    Procura do Follow-up 5 para o 1 para encontrar o √∫ltimo preenchido.
    Retorna: (numero_followup, proximo_followup, temperatura_atual)
    """
    ultimo_follow = 0
    temperatura_atual = "N√£o informada"
    
    # Procura do 5 para o 1 (do mais recente para o mais antigo)
    for i in range(5, 0, -1):
        descricao = dados_negocio['historico_descricoes'][f'D{i}'].strip()
        if descricao:  # Se encontrou descri√ß√£o preenchida
            ultimo_follow = i
            temperatura_atual = dados_negocio['historico_temperaturas'][f'F{i}'].strip() or "N√£o informada"
            break
    
    # Se n√£o encontrou nenhum, significa que est√° no in√≠cio (Follow-up 1)
    if ultimo_follow == 0:
        proximo_follow = 1
    elif ultimo_follow < 5:
        proximo_follow = ultimo_follow + 1
    else:
        proximo_follow = 5  # J√° est√° no √∫ltimo
    
    return ultimo_follow, proximo_follow, temperatura_atual


def pedir_estrategia_ia(dados_negocio):
    """
    Envia o contexto do neg√≥cio para a IA Groq e recebe a estrat√©gia de venda.
    A IA age como um Diretor Comercial experiente.
    """
    # Verifica cache primeiro
    hash_cache = gerar_hash_cache(dados_negocio)
    if hash_cache in cache_analises:
        logger.info(f"Retornando an√°lise em cache para {dados_negocio['negocio']}")
        return cache_analises[hash_cache]

    # Identifica onde a conversa parou
    ultimo_follow, proximo_follow, temperatura_atual = identificar_ultimo_followup(dados_negocio)
    
    # Monta hist√≥rico relevante (apenas os follow-ups preenchidos)
    historico_texto = ""
    for i in range(1, ultimo_follow + 1):
        desc = dados_negocio['historico_descricoes'][f'D{i}'].strip()
        temp = dados_negocio['historico_temperaturas'][f'F{i}'].strip()
        if desc:
            historico_texto += f"Follow-up {i} (Temperatura: {temp or 'N√£o informada'}): {desc}\n"
    
    prompt = f"""Voc√™ √© um Diretor Comercial experiente com anos de experi√™ncia em fechamento de vendas.

AN√ÅLISE DO NEG√ìCIO:
- Nome do Neg√≥cio: {dados_negocio['negocio']}
- Empresa Cliente: {dados_negocio['empresa']}
- Respons√°vel: {dados_negocio['responsavel']}
- Fase Atual: {dados_negocio['fase']}
- √öltimo Follow-up Realizado: #{ultimo_follow}
- Pr√≥ximo Follow-up a Realizar: #{proximo_follow}
- Temperatura Atual: {temperatura_atual}

HIST√ìRICO DE CONVERSAS:
{historico_texto if historico_texto else 'Nenhum follow-up realizado ainda.'}

SUA MISS√ÉO:
Analise a situa√ß√£o e forne√ßa uma orienta√ß√£o estrat√©gica PR√ÅTICA e DIRETA para o Follow-up #{proximo_follow}.

A resposta DEVE conter exatamente estas 3 se√ß√µes:

1. **DIAGN√ìSTICO DA SITUA√á√ÉO:**
   - Identifique claramente a temperatura atual (QUENTE/MORNO/FRIO)
   - Analise o que aconteceu at√© agora
   - Identifique obje√ß√µes, pontos de aten√ß√£o ou oportunidades

2. **ESTRAT√âGIA PARA O PR√ìXIMO PASSO:**
   - O que dizer exatamente no pr√≥ximo contato (mensagem direta)
   - Argumentos de fechamento espec√≠ficos para esta situa√ß√£o
   - Gatilhos mentais ou t√©cnicas de persuas√£o adequadas

3. **A√á√ÉO RECOMENDADA:**
   - Pergunta de fechamento espec√≠fica
   - Pr√≥ximo passo concreto para avan√ßar na venda
   - Prazo sugerido para o follow-up

Seja DIRETO, PR√ÅTICO e FOQUE EM FECHAR A VENDA. N√£o seja gen√©rico."""

    logger.info(f"Processando neg√≥cio: {dados_negocio['negocio']} - Empresa: {dados_negocio['empresa']} - Pr√≥ximo Follow-up: #{proximo_follow}")

    # Lista de modelos v√°lidos (em ordem de prefer√™ncia)
    modelos_validos = [
        'llama-3.3-70b-versatile',  # Modelo atual recomendado
        'llama-3.1-8b-instruct',   # Fallback r√°pido
        'mixtral-8x7b-32768',       # Alternativa Mixtral
        'gemma2-9b-it'              # Alternativa Gemma
    ]
    
    modelo_usar = GROQ_MODEL if GROQ_MODEL in modelos_validos else modelos_validos[0]
    
    # Tenta at√© o limite configurado caso a API esteja ocupada
    for tentativa in range(MAX_RETRIES):
        try:
            response = client.chat.completions.create(
                model=modelo_usar,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=800,
                temperature=0.7
            )
            
            resultado = response.choices[0].message.content
            
            # Salva no cache
            cache_analises[hash_cache] = resultado
            
            logger.info(f"An√°lise gerada com sucesso para {dados_negocio['negocio']} usando modelo {modelo_usar} (tentativa {tentativa + 1})")
            return resultado
            
        except Exception as e:
            error_msg = str(e).lower()
            
            # Se o modelo foi descontinuado, tenta outro modelo
            if "decommissioned" in error_msg or "no longer supported" in error_msg or "model_decommissioned" in error_msg:
                logger.warning(f"Modelo {modelo_usar} foi descontinuado. Tentando modelo alternativo...")
                # Tenta pr√≥ximo modelo da lista
                idx_atual = modelos_validos.index(modelo_usar) if modelo_usar in modelos_validos else 0
                if idx_atual < len(modelos_validos) - 1:
                    modelo_usar = modelos_validos[idx_atual + 1]
                    logger.info(f"Tentando com modelo alternativo: {modelo_usar}")
                    continue
                else:
                    logger.error(f"Todos os modelos testados foram descontinuados")
                    return "Erro: Modelo de IA descontinuado. Por favor, atualize o GROQ_MODEL no arquivo .env para 'llama-3.3-70b-versatile'"
            
            if "rate" in error_msg or "limit" in error_msg or "too many" in error_msg:
                logger.warning(f"Limite de cota Groq atingido. Tentativa {tentativa + 1}/{MAX_RETRIES}")
                if tentativa < MAX_RETRIES - 1:
                    time.sleep(RETRY_DELAY)
                continue
            else:
                logger.error(f"Erro na an√°lise do neg√≥cio {dados_negocio['negocio']}: {str(e)}")
                return f"Erro na an√°lise desta linha: {str(e)}"

    logger.error(f"N√£o foi poss√≠vel gerar an√°lise para {dados_negocio['negocio']} (limite de tentativas excedido)")
    return "N√£o foi poss√≠vel gerar a an√°lise para este item (limite de tentativas excedido)."


def normalizar_nome_coluna(nome):
    """Normaliza nome de coluna removendo acentos, espa√ßos extras, aspas e convertendo para min√∫sculas"""
    import unicodedata
    # Remove aspas primeiro
    nome = str(nome).replace('"', '').replace("'", "").strip()
    # Remove acentos
    nome = unicodedata.normalize('NFD', nome)
    nome = ''.join(char for char in nome if unicodedata.category(char) != 'Mn')
    # Remove espa√ßos extras e converte para min√∫sculas
    nome = ' '.join(nome.split()).lower()
    return nome

def encontrar_coluna_similar(df, nome_procurado):
    """Encontra coluna similar no DataFrame (case-insensitive, sem acentos, ignora 'do')"""
    nome_normalizado = normalizar_nome_coluna(nome_procurado)
    
    # Remove palavras comuns que podem variar para compara√ß√£o
    palavras_ignorar = {'do', 'da', 'de', 'o', 'a', 'e', 'up', 'follow', 'proposta', 'da', 'proposta'}
    
    def limpar_palavras(texto):
        palavras = texto.split()
        return set(p for p in palavras if p not in palavras_ignorar)
    
    palavras_procuradas = limpar_palavras(nome_normalizado)
    
    # Primeiro tenta match exato (sem palavras ignoradas)
    for col in df.columns:
        col_normalizada = normalizar_nome_coluna(str(col))
        if nome_normalizado == col_normalizada:
            logger.debug(f"Match exato encontrado: '{col}' -> '{nome_procurado}'")
            return col
    
    # Depois tenta match por palavras importantes
    melhor_match = None
    melhor_score = 0
    
    for col in df.columns:
        col_normalizada = normalizar_nome_coluna(str(col))
        palavras_coluna = limpar_palavras(col_normalizada)
        
        if palavras_procuradas and palavras_coluna:
            # Calcula quantas palavras importantes est√£o presentes
            palavras_comuns = palavras_procuradas.intersection(palavras_coluna)
            if palavras_procuradas:  # Evita divis√£o por zero
                score = len(palavras_comuns) / len(palavras_procuradas)
            else:
                score = 0
            
            # Se encontrou todas as palavras importantes ou pelo menos 60% (reduzido de 70% para ser mais flex√≠vel)
            if score > melhor_score and score >= 0.6:
                melhor_score = score
                melhor_match = col
                logger.debug(f"Match parcial encontrado (score {score:.2f}): '{col}' -> '{nome_procurado}'")
    
    return melhor_match

def normalizar_colunas_df(df):
    """Normaliza nomes das colunas do DataFrame para nomes padr√£o"""
    mapeamento = {}
    
    # Mapeamento de colunas esperadas para varia√ß√µes poss√≠veis
    colunas_esperadas = {
        'Nome do neg√≥cio': ['nome do negocio', 'nome do neg√≥cio', 'negocio', 'neg√≥cio'],
        'Empresa': ['empresa'],
        'Fase': ['fase'],
        'Responsavel': ['responsavel', 'respons√°vel', 'vendedor', 'usuario', 'usu√°rio', 'usuario', 'usu√°rio'],
        'Temperatura da Proposta Follow 1': ['temperatura da proposta follow 1', 'temperatura follow 1', 'temperatura 1'],
        'Descri√ß√£o Follow up 1': ['descri√ß√£o follow up 1', 'descri√ß√£o do follow up 1', 'descricao follow up 1', 'descricao do follow up 1', 'descri√ß√£o do follow up 1', 'descricao do follow up 1', 'follow up 1'],
        'Temperatura da Proposta Follow 2': ['temperatura da proposta follow 2', 'temperatura follow 2', 'temperatura 2'],
        'Descri√ß√£o Follow up 2': ['descri√ß√£o follow up 2', 'descri√ß√£o do follow up 2', 'descricao follow up 2', 'descricao do follow up 2', 'follow up 2'],
        'Temperatura da Proposta Follow 3': ['temperatura da proposta follow 3', 'temperatura follow 3', 'temperatura 3'],
        'Descri√ß√£o Follow up 3': ['descri√ß√£o follow up 3', 'descri√ß√£o do follow up 3', 'descricao follow up 3', 'descricao do follow up 3', 'follow up 3'],
        'Temperatura da Proposta Follow 4': ['temperatura da proposta follow 4', 'temperatura follow 4', 'temperatura 4'],
        'Descri√ß√£o Follow up 4': ['descri√ß√£o follow up 4', 'descri√ß√£o do follow up 4', 'descricao follow up 4', 'descricao do follow up 4', 'follow up 4'],
        'Temperatura da Proposta Follow 5': ['temperatura da proposta follow 5', 'temperatura follow 5', 'temperatura 5'],
        'Descri√ß√£o Follow up 5': ['descri√ß√£o follow up 5', 'descri√ß√£o do follow up 5', 'descricao follow up 5', 'descricao do follow up 5', 'follow up 5'],
    }
    
    # Para cada coluna esperada, tenta encontrar no DataFrame
    for coluna_esperada, variacoes in colunas_esperadas.items():
        coluna_encontrada = encontrar_coluna_similar(df, coluna_esperada)
        if coluna_encontrada:
            mapeamento[coluna_encontrada] = coluna_esperada
        else:
            # Tenta com varia√ß√µes
            for variacao in variacoes:
                coluna_encontrada = encontrar_coluna_similar(df, variacao)
                if coluna_encontrada:
                    mapeamento[coluna_encontrada] = coluna_esperada
                    break
    
    # Renomeia as colunas encontradas
    if mapeamento:
        df = df.rename(columns=mapeamento)
        logger.info(f"Colunas normalizadas ({len(mapeamento)} colunas): {list(mapeamento.items())[:5]}")
    else:
        logger.warning("Nenhuma coluna foi normalizada. Verifique se os nomes das colunas est√£o corretos.")
    
    # Cria colunas faltantes com valores vazios (para garantir que o sistema funcione)
    colunas_esperadas = [
        'Nome do neg√≥cio', 'Empresa', 'Fase', 'Responsavel',
        'Temperatura da Proposta Follow 1', 'Descri√ß√£o Follow up 1',
        'Temperatura da Proposta Follow 2', 'Descri√ß√£o Follow up 2',
        'Temperatura da Proposta Follow 3', 'Descri√ß√£o Follow up 3',
        'Temperatura da Proposta Follow 4', 'Descri√ß√£o Follow up 4',
        'Temperatura da Proposta Follow 5', 'Descri√ß√£o Follow up 5',
    ]
    
    colunas_criadas = []
    for coluna in colunas_esperadas:
        if coluna not in df.columns:
            df[coluna] = ''  # Cria coluna vazia
            colunas_criadas.append(coluna)
    
    if colunas_criadas:
        logger.info(f"Colunas criadas automaticamente (vazias): {', '.join(colunas_criadas)}")
    
    return df

def validar_planilha(df):
    """
    Valida a planilha de forma flex√≠vel - apenas informa colunas faltantes, mas NUNCA bloqueia.
    Esta fun√ß√£o sempre retorna True e nunca gera exce√ß√µes.
    """
    try:
        colunas_desejadas = [
            'Nome do neg√≥cio', 'Empresa', 'Fase', 'Responsavel',
            'Temperatura da Proposta Follow 1', 'Descri√ß√£o Follow up 1'
        ]

        colunas_faltantes = []
        colunas_encontradas = []
        
        for coluna in colunas_desejadas:
            if coluna in df.columns:
                colunas_encontradas.append(coluna)
            else:
                colunas_faltantes.append(coluna)

        if colunas_encontradas:
            logger.info(f"‚úÖ Colunas encontradas: {', '.join(colunas_encontradas)}")
        
        if colunas_faltantes:
            logger.warning(f"‚ö†Ô∏è Colunas n√£o encontradas (sistema continuar√° funcionando normalmente): {', '.join(colunas_faltantes)}")
            logger.info(f"üìã Todas as colunas dispon√≠veis no arquivo: {', '.join(list(df.columns)[:20])}")

        # SEMPRE retorna True - nunca bloqueia
        return True
    except Exception as e:
        # Se der qualquer erro, apenas loga e continua
        logger.warning(f"Erro na valida√ß√£o (mas continuando): {str(e)}")
        return True  # Sempre retorna True para n√£o bloquear


def ler_planilha_excel(file_path, filename):
    """
    L√™ arquivo Excel/CSV com m√∫ltiplas estrat√©gias de fallback.
    Suporta .xlsx, .xls, .csv e at√© arquivos HTML disfar√ßados de Excel.
    """
    file_ext = filename.lower().split('.')[-1] if '.' in filename else ''
    logger.info(f"Processando arquivo.{file_ext}: {filename}")
    
    df = None
    error_messages = []
    
    # PRIORIDADE 0: Se for CSV, l√™ diretamente (mais simples e confi√°vel)
    if file_ext == 'csv':
        logger.info("Arquivo CSV detectado, lendo diretamente...")
        try:
            # Tenta diferentes separadores e encodings comuns
            separadores = [';', ',', '\t']
            encodings = ['utf-8-sig', 'utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
            
            for encoding in encodings:
                for sep in separadores:
                    try:
                        # Primeiro tenta ler com cabe√ßalho (header='infer')
                        df = pd.read_csv(file_path, sep=sep, encoding=encoding, skipinitialspace=True)
                        if len(df.columns) > 1:
                            logger.info(f"‚úÖ CSV lido com sucesso (separador='{sep}', encoding={encoding}): {len(df)} linhas, {len(df.columns)} colunas")
                            break
                    except Exception:
                        continue
                if df is not None and len(df.columns) > 1:
                    break
                # Se ainda n√£o tem cabe√ßalho reconhec√≠vel, tenta ler sem cabe√ßalho
                try:
                    df = pd.read_csv(file_path, sep=sep, encoding=encoding, header=None, skipinitialspace=True)
                    logger.info(f"‚úÖ CSV lido sem cabe√ßalho (separador='{sep}', encoding={encoding}): {len(df)} linhas, {len(df.columns)} colunas")
                except Exception:
                    df = None
            
            # Se ainda n√£o conseguiu, tenta sem especificar separador (detec√ß√£o autom√°tica)
            if df is None or len(df.columns) <= 1:
                for encoding in encodings:
                    try:
                        df = pd.read_csv(file_path, encoding=encoding, skipinitialspace=True)
                        if len(df.columns) > 1:
                            logger.info(f"‚úÖ CSV lido com detec√ß√£o autom√°tica (encoding={encoding}): {len(df)} linhas, {len(df.columns)} colunas")
                            break
                    except Exception as e:
                        continue
            
            if df is None or len(df.columns) <= 1:
                error_messages.append("N√£o foi poss√≠vel ler o CSV com nenhum separador/encoding testado")
        except Exception as e:
            error_messages.append(f"Erro ao ler CSV: {str(e)}")
        
        if df is not None and not df.empty:
            # Se o CSV n√£o tem cabe√ßalho, atribu√≠mos nomes de colunas esperados com base na posi√ß√£o conhecida
            if df.columns.tolist() == list(range(df.shape[1])):
                # Mapeamento posicional (ajuste conforme seu CSV)
                colunas_pos = [
                    'Empresa',          # 0
                    'Tipo',            # 1 (ignorado)
                    'Fase',            # 2 (ignorado)
                    'Responsavel',     # 3
                    'Data',            # 4 (ignorado)
                    # ... campos intermedi√°rios ignorados ...
                    'Temperatura Atual',  # pen√∫ltimo antes do ID, ajuste conforme necessidade
                ]
                # Preencher at√© o n√∫mero de colunas existentes
                for i, nome in enumerate(colunas_pos):
                    if i < df.shape[1]:
                        df.rename(columns={i: nome}, inplace=True)
                logger.info("Colunas do CSV sem cabe√ßalho foram renomeadas com base em posi√ß√µes conhecidas.")
            return df
    
    # PRIMEIRO: Verifica assinaturas de arquivo Excel v√°lido
    is_valid_excel = False
    is_html = False
    
    try:
        with open(file_path, 'rb') as f:
            header = f.read(8)  # L√™ apenas os primeiros 8 bytes para verificar assinatura
            
            # Assinaturas de arquivos Excel v√°lidos
            excel_signatures = [
                b'\xd0\xcf\x11\xe0\xa1\xb1\x1a\xe1',  # .xls (OLE2 format)
                b'\x50\x4b\x03\x04',  # .xlsx (ZIP format - come√ßa com PK)
                b'\x50\x4b\x05\x06',  # .xlsx (ZIP empty)
                b'\x50\x4b\x07\x08'   # .xlsx (ZIP spanned)
            ]
            
            # Verifica se √© um Excel v√°lido
            for sig in excel_signatures:
                if header.startswith(sig):
                    is_valid_excel = True
                    logger.info(f"Assinatura Excel v√°lida detectada: {sig.hex()}")
                    break
            
            # Se n√£o √© Excel v√°lido, verifica se √© HTML (l√™ mais bytes)
            if not is_valid_excel:
                f.seek(0)
                header_full = f.read(500)
                
                # Detecta HTML de v√°rias formas (incluindo BOM)
                # O caso mais comum: arquivo HTML salvo com extens√£o .xls
                is_html = (
                    header_full.startswith(b'\xef\xbb\xbf<meta') or  # BOM + <meta
                    header_full.startswith(b'<meta') or 
                    header_full.startswith(b'<!DOCTYPE') or 
                    header_full.startswith(b'<html') or
                    header_full.startswith(b'\xef\xbb\xbf<!DOCTYPE') or
                    header_full.startswith(b'\xef\xbb\xbf<html') or
                    (b'<table' in header_full and b'<tr>' in header_full and b'<td>' in header_full) or
                    (b'http-equiv' in header_full and b'Content-type' in header_full)  # Meta tag comum em HTML
                )
                
                if is_html:
                    logger.warning("HTML detectado no arquivo (arquivo HTML salvo com extens√£o .xls/.xlsx)")
    except Exception as e:
        logger.warning(f"Erro ao verificar header do arquivo: {str(e)}")
    
    # PRIORIDADE 1: Tenta ler como Excel primeiro (APENAS se tem assinatura v√°lida E n√£o √© HTML)
    if is_valid_excel and not is_html:
        logger.info("Tentando ler como arquivo Excel v√°lido...")
        
        if file_ext == 'xls':
            # Para .xls, tenta xlrd primeiro (mais compat√≠vel)
            try:
                df = pd.read_excel(file_path, engine='xlrd')
                logger.info("‚úÖ Arquivo .xls lido com sucesso usando xlrd")
            except Exception as e1:
                logger.warning(f"xlrd falhou: {str(e1)}")
                error_messages.append(f"xlrd: {str(e1)}")
                
                # Tenta openpyxl como fallback
                try:
                    df = pd.read_excel(file_path, engine='openpyxl')
                    logger.info("‚úÖ Arquivo .xls lido com sucesso usando openpyxl (fallback)")
                except Exception as e2:
                    logger.warning(f"openpyxl tamb√©m falhou: {str(e2)}")
                    error_messages.append(f"openpyxl: {str(e2)}")
                
                # Tenta sem engine espec√≠fica
                if df is None:
                    try:
                        df = pd.read_excel(file_path)
                        logger.info("‚úÖ Arquivo .xls lido sem engine espec√≠fica")
                    except Exception as e3:
                        error_messages.append(f"default: {str(e3)}")
        
        elif file_ext == 'xlsx':
            # Para .xlsx, tenta openpyxl primeiro
            try:
                df = pd.read_excel(file_path, engine='openpyxl')
                logger.info("‚úÖ Arquivo .xlsx lido com sucesso usando openpyxl")
            except Exception as e1:
                logger.warning(f"openpyxl falhou: {str(e1)}")
                error_messages.append(f"openpyxl: {str(e1)}")
                
                # Tenta xlrd como fallback
                try:
                    df = pd.read_excel(file_path, engine='xlrd')
                    logger.info("‚úÖ Arquivo .xlsx lido com sucesso usando xlrd (fallback)")
                except Exception as e2:
                    logger.warning(f"xlrd tamb√©m falhou: {str(e2)}")
                    error_messages.append(f"xlrd: {str(e2)}")
                
                # Tenta sem engine espec√≠fica
                if df is None:
                    try:
                        df = pd.read_excel(file_path)
                        logger.info("‚úÖ Arquivo .xlsx lido sem engine espec√≠fica")
                    except Exception as e3:
                        error_messages.append(f"default: {str(e3)}")
        
        # Se ainda n√£o conseguiu e tem assinatura Excel, tenta tratamento especial
        if df is None and is_valid_excel:
            logger.warning("Arquivo tem assinatura Excel mas n√£o foi poss√≠vel ler. Tentando tratamento especial...")
            # Tenta remover BOM se existir e ler novamente
            try:
                with open(file_path, 'rb') as f:
                    content = f.read()
                
                # Remove BOM se existir no in√≠cio
                if content.startswith(b'\xef\xbb\xbf'):
                    logger.info("Removendo BOM do arquivo...")
                    content = content[3:]
                    temp_path = file_path + '_no_bom.xls'
                    with open(temp_path, 'wb') as f:
                        f.write(content)
                    
                    try:
                        df = pd.read_excel(temp_path, engine='xlrd')
                        logger.info("‚úÖ Arquivo lido ap√≥s remover BOM")
                    except:
                        pass
                    finally:
                        try:
                            os.unlink(temp_path)
                        except:
                            pass
            except Exception as e:
                logger.warning(f"Tratamento especial falhou: {str(e)}")
    
    # PRIORIDADE 2: Se detectou HTML (mesmo que tenha extens√£o .xls/.xlsx), tenta converter HTML PRIMEIRO
    if is_html:
        logger.warning("Conte√∫do HTML detectado, tentando converter HTML para DataFrame...")
        
        # Estrat√©gia 1: Remove BOM primeiro e tenta pd.read_html
        try:
            with open(file_path, 'rb') as f:
                content_bytes = f.read()
            
            # Remove BOM se existir
            if content_bytes.startswith(b'\xef\xbb\xbf'):
                logger.info("Removendo BOM do arquivo HTML...")
                content_bytes = content_bytes[3:]
            
            # Salva temporariamente sem BOM
            temp_html_path = file_path + '_temp_clean.html'
            with open(temp_html_path, 'wb') as f:
                f.write(content_bytes)
            
            # Tenta ler HTML com diferentes encodings
            encodings_to_try = ['utf-8', 'utf-8-sig', 'latin-1', 'iso-8859-1', 'cp1252']
            for encoding in encodings_to_try:
                try:
                    df_html = pd.read_html(temp_html_path, encoding=encoding)
                    if df_html and len(df_html) > 0:
                        # Pega a primeira tabela com mais colunas (geralmente √© a principal)
                        df = max(df_html, key=lambda x: len(x.columns) if not x.empty else 0)
                        if not df.empty:
                            logger.info(f"‚úÖ HTML convertido com sucesso (encoding={encoding}): {len(df)} linhas, {len(df.columns)} colunas")
                            break
                except Exception as e1:
                    if encoding == encodings_to_try[0]:
                        logger.warning(f"pd.read_html com encoding {encoding} falhou: {str(e1)}")
                        error_messages.append(f"read_html({str(e1)})")
                    continue
            
            # Remove arquivo tempor√°rio
            try:
                os.unlink(temp_html_path)
            except:
                pass
                
        except Exception as e:
            logger.warning(f"Erro ao processar HTML: {str(e)}")
            error_messages.append(f"process_html: {str(e)}")
        
        # Estrat√©gia 2: Se ainda n√£o conseguiu, tenta direto no arquivo original
        if df is None:
            encodings_to_try = ['utf-8', 'utf-8-sig', 'latin-1', 'iso-8859-1', 'cp1252']
            for encoding in encodings_to_try:
                try:
                    df_html = pd.read_html(file_path, encoding=encoding)
                    if df_html and len(df_html) > 0:
                        df = max(df_html, key=lambda x: len(x.columns) if not x.empty else 0)
                        if not df.empty:
                            logger.info(f"‚úÖ HTML convertido diretamente (encoding={encoding}): {len(df)} linhas, {len(df.columns)} colunas")
                            break
                except Exception as e1:
                    continue
        
        # Estrat√©gia 2: Remove BOM manualmente e tenta novamente
        if df is None:
            try:
                with open(file_path, 'rb') as f:
                    content_bytes = f.read()
                
                # Remove BOM se existir
                if content_bytes.startswith(b'\xef\xbb\xbf'):
                    content_bytes = content_bytes[3:]
                
                # Salva temporariamente sem BOM
                temp_html_path = file_path + '_clean.html'
                with open(temp_html_path, 'wb') as f:
                    f.write(content_bytes)
                
                df_html = pd.read_html(temp_html_path, encoding='utf-8')
                if df_html and len(df_html) > 0:
                    df = max(df_html, key=lambda x: len(x.columns) if not x.empty else 0)
                    if not df.empty:
                        logger.info(f"HTML convertido ap√≥s remover BOM: {len(df)} linhas, {len(df.columns)} colunas")
                
                # Remove arquivo tempor√°rio
                try:
                    os.unlink(temp_html_path)
                except:
                    pass
            except Exception as e2:
                logger.warning(f"Convers√£o HTML com BOM removido falhou: {str(e2)}")
                error_messages.append(f"read_html_bom({str(e2)})")
        
        # Estrat√©gia 3: Tenta ler como CSV (√†s vezes HTML √© salvo como CSV)
        if df is None:
            try:
                for sep in [';', ',', '\t']:
                    try:
                        df_test = pd.read_csv(file_path, sep=sep, encoding='utf-8-sig', skiprows=0)
                        if len(df_test.columns) > 1:  # Se encontrou m√∫ltiplas colunas
                            df = df_test
                            logger.info(f"HTML lido como CSV com separador '{sep}': {len(df)} linhas, {len(df.columns)} colunas")
                            break
                    except:
                        continue
            except Exception as e4:
                logger.warning(f"Leitura como CSV falhou: {str(e4)}")
    
    # PRIORIDADE 3: Se n√£o √© HTML e tem extens√£o .xls/.xlsx mas n√£o tem assinatura v√°lida, tenta ler como Excel
    if df is None and not is_html and file_ext in ['xls', 'xlsx']:
        logger.info("Tentando ler como Excel (extens√£o .xls/.xlsx mas sem assinatura detectada)...")
        if file_ext == 'xls':
            try:
                df = pd.read_excel(file_path, engine='xlrd')
                logger.info("‚úÖ Arquivo .xls lido com sucesso usando xlrd")
            except Exception as e1:
                logger.warning(f"xlrd falhou: {str(e1)}")
                error_messages.append(f"xlrd: {str(e1)}")
                try:
                    df = pd.read_excel(file_path, engine='openpyxl')
                    logger.info("‚úÖ Arquivo .xls lido com sucesso usando openpyxl")
                except Exception as e2:
                    error_messages.append(f"openpyxl: {str(e2)}")
        elif file_ext == 'xlsx':
            try:
                df = pd.read_excel(file_path, engine='openpyxl')
                logger.info("‚úÖ Arquivo .xlsx lido com sucesso usando openpyxl")
            except Exception as e1:
                logger.warning(f"openpyxl falhou: {str(e1)}")
                error_messages.append(f"openpyxl: {str(e1)}")
                try:
                    df = pd.read_excel(file_path, engine='xlrd')
                    logger.info("‚úÖ Arquivo .xlsx lido com sucesso usando xlrd")
                except Exception as e2:
                    error_messages.append(f"xlrd: {str(e2)}")
    
    # Se ainda n√£o conseguiu ler, d√° mensagem de erro clara
    if df is None:
        if is_html:
            raise ValueError(
                "O arquivo parece ser HTML (p√°gina web) e n√£o um arquivo Excel v√°lido. "
                "Por favor, abra o arquivo no Excel e salve como '.xlsx' ou '.xls' antes de enviar. "
                f"Erros de convers√£o: {', '.join(error_messages) if error_messages else 'N√£o foi poss√≠vel converter HTML'}"
            )
        elif is_valid_excel:
            all_errors = ", ".join(error_messages) if error_messages else "Erro desconhecido"
            raise ValueError(
                f"O arquivo tem assinatura Excel v√°lida mas n√£o foi poss√≠vel ler. "
                f"O arquivo pode estar corrompido. Erros: {all_errors}. "
                f"Tente abrir o arquivo no Excel e salvar novamente."
            )
        else:
            all_errors = ", ".join(error_messages) if error_messages else "Erro desconhecido"
            raise ValueError(
                f"N√£o foi poss√≠vel ler o arquivo Excel. "
                f"Verifique se o arquivo n√£o est√° corrompido. Erros: {all_errors}. "
                f"Se o problema persistir, tente abrir o arquivo no Excel e salvar novamente como .xlsx"
            )
    
    if df.empty:
        raise ValueError("O arquivo est√° vazio ou n√£o cont√©m dados v√°lidos")
    
    return df


# ==================== ROTAS ====================

@app.route('/')
def index():
    """P√°gina inicial com formul√°rio de upload"""
    return render_template('index.html')


@app.route('/processar', methods=['POST'])
def processar():
    """Processa a planilha enviada e gera an√°lises estrat√©gicas"""
    if 'file' not in request.files:
        logger.error("Nenhum arquivo enviado na requisi√ß√£o")
        flash('Nenhum arquivo selecionado', 'error')
        return redirect(url_for('index'))
    
    file = request.files['file']
    
    if file.filename == '':
        logger.error("Nome de arquivo vazio")
        flash('Nenhum arquivo selecionado', 'error')
        return redirect(url_for('index'))
    
    if not allowed_file(file.filename):
        logger.error(f"Formato de arquivo inv√°lido: {file.filename}")
        flash('Formato de arquivo inv√°lido. Envie arquivos Excel (.xlsx, .xls) ou CSV (.csv)', 'error')
        return redirect(url_for('index'))
    
    try:
        logger.info(f"Processando arquivo: {file.filename}")
        
        # Salva temporariamente
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
            file.save(tmp_file.name)
            tmp_file_path = tmp_file.name
        
        try:
            # L√™ a planilha
            df = ler_planilha_excel(tmp_file_path, file.filename)
            
            # Limpeza dos dados
            df = df.fillna("")
            # Remove aspas e espa√ßos extras dos nomes das colunas
            df.columns = df.columns.str.strip().str.replace('"', '').str.replace("'", "")
            
            logger.info(f"Arquivo lido: {len(df)} linhas, {len(df.columns)} colunas")
            logger.info(f"Colunas encontradas (ap√≥s limpeza): {list(df.columns)[:15]}")
            
            # Normaliza nomes das colunas (aceita varia√ß√µes como acentos, "do", etc)
            df = normalizar_colunas_df(df)
            
            logger.info(f"Colunas ap√≥s normaliza√ß√£o: {list(df.columns)[:15]}")
            
            # Valida estrutura (apenas informa, n√£o bloqueia - NUNCA bloqueia)
            try:
                validar_planilha(df)
            except Exception as e:
                # Se por algum motivo der erro na valida√ß√£o, apenas loga e continua
                logger.warning(f"Valida√ß√£o retornou erro (mas continuando): {str(e)}")
            
            # Verifica se tem pelo menos algumas colunas b√°sicas
            colunas_basicas = ['Nome do neg√≥cio', 'Empresa', 'Fase', 'Responsavel']
            tem_colunas_basicas = any(col in df.columns for col in colunas_basicas)
            
            if not tem_colunas_basicas:
                logger.warning("Nenhuma coluna b√°sica encontrada, mas continuando processamento...")
                flash('Aviso: Algumas colunas esperadas n√£o foram encontradas. O sistema continuar√° processando com os dados dispon√≠veis.', 'warning')
            
            # Processa cada linha
            relatorio_final = []
            linhas_processadas = 0
            linhas_com_erro = 0

            for index, linha in df.iterrows():
                try:
                    # Monta o dicion√°rio de dados da linha (usa valores padr√£o se coluna n√£o existir)
                    # Busca colunas de forma flex√≠vel
                    def buscar_coluna(coluna_principal, alternativas=None):
                        """Busca coluna no DataFrame, tentando varia√ß√µes e, se necess√°rio, posi√ß√µes conhecidas."""
                        # Tenta coluna principal
                        if coluna_principal in df.columns:
                            valor = linha.get(coluna_principal, '')
                            if pd.notna(valor):
                                return str(valor).strip()
                        # Tenta alternativas
                        if alternativas:
                            for alt in alternativas:
                                if alt in df.columns:
                                    valor = linha.get(alt, '')
                                    if pd.notna(valor):
                                        return str(valor).strip()
                        # Fallback: tenta usar posi√ß√£o baseada em nomes conhecidos
                        pos_map = {
                            'Empresa': 0,
                            'Responsavel': 3,
                            'Temperatura da Proposta Follow 1': -2,  # pen√∫ltimo campo antes do ID (ajuste conforme CSV)
                        }
                        if coluna_principal in pos_map:
                            idx = pos_map[coluna_principal]
                            if isinstance(idx, int) and abs(idx) < len(linha):
                                valor = linha.iloc[idx] if hasattr(linha, 'iloc') else linha[idx]
                                if pd.notna(valor):
                                    return str(valor).strip()
                        return ''
                    
                    item = {
                        "negocio": buscar_coluna('Nome do neg√≥cio', ['Nome do negocio', 'Neg√≥cio', 'Negocio']) or f'Neg√≥cio {index + 1}',
                        "fase": buscar_coluna('Fase') or 'N√£o informada',
                        "responsavel": buscar_coluna('Responsavel', ['Respons√°vel', 'Vendedor', 'Usuario', 'Usu√°rio']) or 'N√£o informado',
                        "empresa": buscar_coluna('Empresa') or 'N√£o informada',
                        "historico_temperaturas": {
                            "F1": buscar_coluna('Temperatura da Proposta Follow 1', ['Temperatura Follow 1', 'Temperatura 1']),
                            "F2": buscar_coluna('Temperatura da Proposta Follow 2', ['Temperatura Follow 2', 'Temperatura 2']),
                            "F3": buscar_coluna('Temperatura da Proposta Follow 3', ['Temperatura Follow 3', 'Temperatura 3']),
                            "F4": buscar_coluna('Temperatura da Proposta Follow 4', ['Temperatura Follow 4', 'Temperatura 4']),
                            "F5": buscar_coluna('Temperatura da Proposta Follow 5', ['Temperatura Follow 5', 'Temperatura 5']),
                        },
                        "historico_descricoes": {
                            "D1": buscar_coluna('Descri√ß√£o Follow up 1', ['Descri√ß√£o do Follow up 1', 'Descricao Follow up 1', 'Follow up 1']),
                            "D2": buscar_coluna('Descri√ß√£o Follow up 2', ['Descri√ß√£o do Follow up 2', 'Descricao Follow up 2', 'Follow up 2']),
                            "D3": buscar_coluna('Descri√ß√£o Follow up 3', ['Descri√ß√£o do Follow up 3', 'Descricao Follow up 3', 'Follow up 3']),
                            "D4": buscar_coluna('Descri√ß√£o Follow up 4', ['Descri√ß√£o do Follow up 4', 'Descricao Follow up 4', 'Follow up 4']),
                            "D5": buscar_coluna('Descri√ß√£o Follow up 5', ['Descri√ß√£o do Follow up 5', 'Descricao Follow up 5', 'Follow up 5']),
                        }
                    }
                    
                    # Pula linhas completamente vazias (mas √© mais flex√≠vel agora)
                    if (not item['negocio'] or item['negocio'] == f'Neg√≥cio {index + 1}') and \
                       (not item['empresa'] or item['empresa'] == 'N√£o informada') and \
                       not any(item['historico_descricoes'].values()):
                        logger.info(f"Pulando linha {index + 1} - dados completamente vazios")
                        continue
                    
                    # Identifica follow-ups para exibi√ß√£o
                    ultimo_follow, proximo_follow, temperatura_atual = identificar_ultimo_followup(item)
                    item["ultimo_follow"] = ultimo_follow
                    item["proximo_follow"] = proximo_follow
                    item["temperatura_atual"] = temperatura_atual
                    
                    # Chama a IA para an√°lise estrat√©gica
                    item["analise_proximo_passo"] = pedir_estrategia_ia(item)
                    
                    # Pausa para n√£o sobrecarregar a API
                    time.sleep(REQUEST_DELAY)
                    
                    relatorio_final.append(item)
                    linhas_processadas += 1
                    
                    # Progress log
                    if (index + 1) % 10 == 0:
                        logger.info(f"Progresso: {index + 1}/{len(df)} linhas processadas")
                        
                except Exception as e:
                    logger.error(f"Erro ao processar linha {index + 1}: {str(e)}")
                    linhas_com_erro += 1
                    continue

            logger.info(f"Processamento conclu√≠do: {linhas_processadas} sucessos, {linhas_com_erro} erros")
            
            if linhas_processadas == 0:
                flash('Nenhuma linha v√°lida encontrada na planilha', 'warning')
                return redirect(url_for('index'))
            
            # Armazena na sess√£o
            import uuid
            relatorio_id = str(uuid.uuid4())[:8]
            
            if 'relatorios' not in session:
                session['relatorios'] = {}
            session['relatorios'][relatorio_id] = relatorio_final
            session['relatorio_id_atual'] = relatorio_id
            session['relatorio_data'] = relatorio_final
            
            logger.info(f"Relat√≥rio armazenado com ID: {relatorio_id}")
            
            return render_template('relatorio.html', relatorio=relatorio_final, total=len(relatorio_final))
            
        finally:
            # Remove arquivo tempor√°rio
            try:
                os.unlink(tmp_file_path)
            except:
                pass

    except ValueError as e:
        # S√≥ bloqueia se for erro cr√≠tico (n√£o relacionado a valida√ß√£o de colunas)
        error_msg = str(e)
        if "Colunas obrigat√≥rias" in error_msg or "colunas faltando" in error_msg.lower():
            # Se for erro de colunas, apenas avisa mas continua
            logger.warning(f"Aviso de valida√ß√£o (continuando processamento): {error_msg}")
            flash(f'Aviso: {error_msg}. O sistema continuar√° processando com os dados dispon√≠veis.', 'warning')
            # N√ÉO retorna redirect - continua processamento
        else:
            # Outros erros ValueError s√£o cr√≠ticos
            logger.error(f"Erro cr√≠tico: {error_msg}")
            flash(f'Erro ao processar arquivo: {error_msg}', 'error')
            return redirect(url_for('index'))
    except Exception as e:
        logger.error(f"Erro cr√≠tico ao processar a planilha: {str(e)}")
        flash(f'Erro ao processar arquivo: {str(e)}', 'error')
        return redirect(url_for('index'))


@app.route('/gerar_pdf')
def gerar_pdf():
    """Gera PDF profissional do relat√≥rio de an√°lises"""
    try:
        relatorio_final = None
        
        if 'relatorio_data' in session and session['relatorio_data']:
            relatorio_final = session['relatorio_data']
        elif 'relatorios' in session and session['relatorios']:
            ultimo_id = list(session['relatorios'].keys())[-1]
            relatorio_final = session['relatorios'][ultimo_id]
        
        if not relatorio_final:
            logger.error("Dados do relat√≥rio n√£o encontrados na sess√£o")
            flash('Dados do relat√≥rio n√£o encontrados. Por favor, processe a planilha novamente.', 'error')
            return redirect(url_for('index'))
        
        total = len(relatorio_final)
        logger.info(f"Gerando PDF para {total} itens")
        
        # Cria buffer em mem√≥ria
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=18)
        
        # Estilos
        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=20,
            spaceAfter=30,
            alignment=1,
            textColor=colors.HexColor('#2c3e50')
        )
        
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontSize=14,
            spaceAfter=12,
            textColor=colors.HexColor('#34495e')
        )
        
        normal_style = ParagraphStyle(
            'CustomNormal',
            parent=styles['Normal'],
            fontSize=10,
            spaceAfter=6,
            leading=14
        )
        
        # Conte√∫do do PDF
        story = []
        
        # T√≠tulo
        story.append(Paragraph("Relat√≥rio de An√°lise Estrat√©gica de CRM", title_style))
        story.append(Spacer(1, 20))
        
        # Data e resumo
        data_atual = datetime.now().strftime("%d/%m/%Y %H:%M")
        story.append(Paragraph(f"<b>Data:</b> {data_atual}", normal_style))
        story.append(Paragraph(f"<b>Total de Neg√≥cios Analisados:</b> {total}", normal_style))
        story.append(Spacer(1, 20))
        
        # An√°lises detalhadas
        for i, item in enumerate(relatorio_final, 1):
            # Cabe√ßalho do Cliente
            story.append(Paragraph(f"<b>{i}. {item['negocio']}</b>", heading_style))
            story.append(Paragraph(f"<b>Empresa:</b> {item['empresa']}", normal_style))
            story.append(Paragraph(f"<b>Respons√°vel:</b> {item['responsavel']}", normal_style))
            
            # Status Atual
            story.append(Paragraph(f"<b>Fase:</b> {item['fase']}", normal_style))
            story.append(Paragraph(f"<b>Temperatura Atual:</b> {item.get('temperatura_atual', 'N√£o informada')}", normal_style))
            
            # Follow-up
            ultimo = item.get('ultimo_follow', 0)
            proximo = item.get('proximo_follow', 1)
            if ultimo > 0:
                story.append(Paragraph(f"<b>√öltimo Follow-up Realizado:</b> #{ultimo}", normal_style))
            story.append(Paragraph(f"<b>Pr√≥ximo Follow-up:</b> #{proximo}", normal_style))
            story.append(Spacer(1, 10))
            
            # Plano de A√ß√£o (IA)
            story.append(Paragraph("<b>Plano de A√ß√£o Estrat√©gico (IA):</b>", normal_style))
            analise_text = item.get('analise_proximo_passo', 'An√°lise n√£o dispon√≠vel')
            # Limita tamanho para n√£o quebrar o PDF
            if len(analise_text) > 1500:
                analise_text = analise_text[:1500] + '...'
            story.append(Paragraph(analise_text, normal_style))
            story.append(Spacer(1, 20))
            
            # Quebra de p√°gina entre empresas (exceto na √∫ltima)
            if i < total:
                story.append(PageBreak())
        
        # Rodap√©
        story.append(Spacer(1, 20))
        story.append(Paragraph("<b>Relat√≥rio gerado por:</b> Sistema de Automa√ß√£o de Vendas com IA", normal_style))
        story.append(Paragraph(f"<b>Emiss√£o:</b> {data_atual}", normal_style))
        
        # Gera o PDF
        doc.build(story)
        buffer.seek(0)
        
        # Prepara resposta
        response = make_response(buffer.getvalue())
        response.headers['Content-Type'] = 'application/pdf'
        response.headers['Content-Disposition'] = f'inline; filename=relatorio_analise_{datetime.now().strftime("%Y%m%d_%H%M")}.pdf'
        
        logger.info(f"PDF gerado com sucesso: {total} itens")
        return response
        
    except Exception as e:
        logger.error(f"Erro ao gerar PDF: {str(e)}")
        flash(f'Erro ao gerar PDF: {str(e)}', 'error')
        return redirect(url_for('index'))


@app.route('/limpar_sessao')
def limpar_sessao():
    """Limpa dados da sess√£o para permitir novos processamentos"""
    try:
        keys_to_clear = ['relatorio_data', 'relatorios', 'relatorio_id_atual']
        for key in keys_to_clear:
            if key in session:
                session.pop(key, None)
        
        logger.info("Sess√£o de relat√≥rios limpa com sucesso")
        flash('Sess√£o limpa. Voc√™ pode processar novas planilhas agora.', 'success')
        
    except Exception as e:
        logger.error(f"Erro ao limpar sess√£o: {str(e)}")
        flash(f'Erro ao limpar sess√£o: {str(e)}', 'error')
    
    return redirect(url_for('index'))


# ==================== INICIALIZA√á√ÉO ====================

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('FLASK_DEBUG', 'True').lower() == 'true'
    
    logger.info(f"Iniciando servidor Flask na porta {port} (debug={debug})")
    logger.info(f"Usando API Groq com modelo: {GROQ_MODEL}")
    app.run(debug=debug, port=port)
